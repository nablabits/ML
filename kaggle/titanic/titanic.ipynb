{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index**\n",
    "* [Tutorial by Alexis Cook](#Tutorial-by-Alexis-Cook)\n",
    "* [Data exploration](#Data-Exploration)\n",
    "* [Bayesian approach](#Bayesian-approach)\n",
    "* [Tutorial by Jeffd23](#Tutorial-approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')  \n",
    "testdf = pd.read_csv('test.csv')  # the data without class for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial by Alexis Cook\n",
    "(https://www.kaggle.com/alexisbcook/titanic-tutorial)\n",
    "\n",
    "Just a RandomForest classifier over Passenger class, sex, siblings and parents\n",
    "\n",
    "After submission it scored 76% (I've killed/revived the other 24%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = df.Survived\n",
    "features = ['Pclass', 'Sex', 'SibSp', 'Parch']\n",
    "\n",
    "# Convert categories into numbers\n",
    "X = pd.get_dummies(df[features])\n",
    "X_test = pd.get_dummies(testdf[features])\n",
    "\n",
    "# Instantiate the classifier, train and predict\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "pd.DataFrame({'PassengerId': testdf.PassengerId, 'Survived':predictions}).to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Show a visualization about rough numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='ticks')\n",
    "\n",
    "d0 = df.copy()\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "f = d0[d0.Age.isna()]\n",
    "d0.loc[f.index, 'Age'] = -1\n",
    "\n",
    "sns.countplot(d0.Survived, ax=axes[0, 0])\n",
    "sns.countplot(d0.Sex, ax=axes[0, 1])\n",
    "sns.distplot(d0.Age, kde=False, ax=axes[0,2])\n",
    "sns.countplot(d0.Pclass, ax=axes[1, 0])\n",
    "sns.countplot(d0.SibSp, ax=axes[1, 1])\n",
    "sns.countplot(d0.Parch, ax=axes[1, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian approach\n",
    "Try to predict the survivors using simple bayes' theorem rules.\n",
    "Set people with less than 50% chances of survive as dead. After submitting, this approach gave 69% accuracy\n",
    "\n",
    "Get live chances given sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Sex chances given live status\n",
    "d1 = df[['Sex', 'Survived']]\n",
    "f = d1.Survived == 0\n",
    "d2, d3 = d1[f], d1[~f]  # Dead/alive\n",
    "d2 = d2.groupby('Sex').count()\n",
    "d3 = d3.groupby('Sex').count()\n",
    "\n",
    "# Merge on sex\n",
    "d1 = pd.merge(d2, d3, left_index=True, right_index=True)\n",
    "\n",
    "# Dead/alive percents\n",
    "da = d1.sum(axis=0) / d1.sum().sum()\n",
    "\n",
    "# Compute female & male alive, female & male dead\n",
    "f, m = d1.values.sum(axis=1)  # totals by sex\n",
    "fd, fa, md, ma = d1.values.ravel()\n",
    "\n",
    "# get live chances given sex\n",
    "data = {\n",
    "    'Female': [fa/f, fd/f],\n",
    "    'Male': [ma/m, md/m],}\n",
    "L_S = pd.DataFrame(data=data, index=['Alive', 'Dead'])\n",
    "L_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the live chances given sex, calculate the live chances given the Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Filter women\n",
    "f = df.Sex == 'female'\n",
    "d0 = df[f][['Survived', 'Pclass']]\n",
    "\n",
    "# Filter alive status\n",
    "f = d0.Survived == 0\n",
    "d1, d2 = d0[f], d0[~f]  # dead/alive\n",
    "\n",
    "d1, d2 = [data.groupby('Pclass').count() for data in (d1, d2)]\n",
    "\n",
    "d0 = pd.merge(d1, d2, left_index=True, right_index=True, suffixes=('_0', '_1'))\n",
    "d0 = d0/d0.sum()\n",
    "\n",
    "A1 = d0.iat[0, 1] / d0.iloc[0, :].sum()\n",
    "A2 = d0.iat[1, 1] / d0.iloc[1, :].sum()\n",
    "A3 = d0.iat[2, 1] / d0.iloc[2, :].sum()\n",
    "\n",
    "pf0 = [A1, A2, A3]  # Surviving chances by class being female\n",
    "\n",
    "# Filter men\n",
    "f = df.Sex == 'male'\n",
    "d0 = df[f][['Survived', 'Pclass']]\n",
    "\n",
    "# Filter alive status\n",
    "f = d0.Survived == 0\n",
    "d1, d2 = d0[f], d0[~f]  # dead/alive\n",
    "\n",
    "d1, d2 = [data.groupby('Pclass').count() for data in (d1, d2)]\n",
    "\n",
    "d0 = pd.merge(d1, d2, left_index=True, right_index=True, suffixes=('_0', '_1'))\n",
    "d0 = d0/d0.sum()\n",
    "\n",
    "A1 = d0.iat[0, 1] / d0.iloc[0, :].sum()\n",
    "A2 = d0.iat[1, 1] / d0.iloc[1, :].sum()\n",
    "A3 = d0.iat[2, 1] / d0.iloc[2, :].sum()\n",
    "\n",
    "pm0 = [A1, A2, A3]  # Surviving chances by class being male\n",
    "\n",
    "\n",
    "pd.DataFrame({'female': pf0, 'male': pm0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Now set, f3, m3, m2 as dead and m1 f2 f1 as survived\n",
    "d0 = testdf.copy()\n",
    "\n",
    "d0['Survived'] = 0\n",
    "\n",
    "# revive m1, f2 & f1\n",
    "f = (\n",
    "    ((d0.Sex == 'male') & (d0.Pclass == 1)) |\n",
    "    ((d0.Sex == 'female') & (d0.Pclass.isin((1, 2)))))\n",
    "d0.loc[d0[f].index, 'Survived'] = 1\n",
    "\n",
    "pd.DataFrame({'PassengerId': testdf.PassengerId, 'Survived':predictions}).to_csv('my_submission.csv', index=False)\n",
    "d0[['PassengerId', 'Survived']].to_csv('bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial approach\n",
    "\n",
    "Now we'll work through a tutorial on [kaggle](https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish) made by jeffd23\n",
    "\n",
    "After submission it scored 74% (less than the first tutorial but better than the bayes approach). Notice that cross validation gave 83% of accuracy\n",
    "\n",
    "## Fisrt plot some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df.Embarked, y=df.Survived, hue=df.Sex);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=df.Pclass, y=df.Survived, hue=df.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "d0 = df.copy()\n",
    "t0 = testdf.copy()\n",
    "\n",
    "for dataframe in (d0, t0):\n",
    "    # Build age bins\n",
    "    dataframe.loc[:, 'Age'] = dataframe.Age.fillna(-.5)\n",
    "    bins = [-1, 0, 5, 12, 18, 25, 35, 60, 120, ]\n",
    "    labels = ['unknown', 'baby', 'child', 'teenager', 'student', 'young adult', 'adult', 'senior', ]\n",
    "    dataframe.loc[:, 'Age'] = pd.cut(dataframe.Age, bins, labels=labels)\n",
    "\n",
    "    # Simplify cabin names\n",
    "    dataframe.loc[:, 'Cabin'] = dataframe.Cabin.fillna('N')\n",
    "    dataframe.loc[:, 'Cabin'] = dataframe.Cabin.apply(lambda x: x[0])\n",
    "\n",
    "    # Make fares categorical\n",
    "    dataframe.loc[:, 'Fare'] = dataframe.Fare.fillna(-.5)\n",
    "    bins = [-1, 0, 8, 14, 31, 520, ]\n",
    "    labels = ['unknown', '1st', '2nd', '3rd', '4th']\n",
    "    dataframe.loc[:, 'Fare'] = pd.cut(dataframe.Fare, bins, labels=labels)\n",
    "\n",
    "    # Normalize names\n",
    "    d1 = dataframe.Name.apply(lambda x: x.split(',')[1].split('.')[0])\n",
    "    dataframe['Title'] = d1.str.replace(' ', '')\n",
    "\n",
    "    # A couple of irregular ones\n",
    "    d1 = dataframe[dataframe.Title.str.contains('Jonkheer')]\n",
    "    d2 = dataframe[dataframe.Title.str.contains('Countess')]\n",
    "    dataframe.loc[d1.index, 'Title'] = 'Mr'\n",
    "    dataframe.loc[d2.index, 'Title'] = 'Mrs'  # In her Age group are majority\n",
    "    \n",
    "    # Finally, drop some columns\n",
    "    dataframe.drop(columns=['Ticket', 'Embarked', 'Name', 'PassengerId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "d0.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the data\n",
    "In this step we'll encode the labels into numbers that can run in a ML algorithm. We should build a dataframe with all the training and testing features so the encoding will see all possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Title']\n",
    "combined_df = pd.concat((d0[features], t0[features]))  # Join all possible values\n",
    "for feat in features:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(combined_df[feat])\n",
    "    d0.loc[:, feat] = le.transform(d0[feat])\n",
    "    t0.loc[:, feat] = le.transform(t0[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = d0.drop(columns=['Survived'])\n",
    "y_all = d0['Survived']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(x_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(10)\n",
    "outcomes = []\n",
    "fold = 0\n",
    "for train_idx, test_idx in kf.split(X_all):\n",
    "    fold += 1\n",
    "    X_train, y_train = X_all.values[train_idx], y_all.values[train_idx]\n",
    "    X_test, y_test = X_all.values[test_idx], y_all.values[test_idx]\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_hat)\n",
    "    outcomes.append(accuracy)\n",
    "    print('Fold {} accuracy: {}'.format(fold, accuracy))\n",
    "np.mean(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the submission\n",
    "y_hat = clf.predict(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(index=testdf.PassengerId, data=y_hat, name='Survived').to_csv('jd-go.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
