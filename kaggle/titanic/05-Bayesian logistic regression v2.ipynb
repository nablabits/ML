{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')  \n",
    "testdf = pd.read_csv('test.csv')  # the data without class for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian logistic regression v2\n",
    "\n",
    "In this approach we'll make a dual model: one for the known ages and the other for the unknown.\n",
    "\n",
    "The train/test splits were chosen with the same ratio as the train test provided data.\n",
    "\n",
    "---\n",
    "\n",
    "### 1st attempt\n",
    "In the submitted data the unknown model performed better than the known one. In further submissions of this model happens the other way around (and that also matches my intuition derived from previous tests)\n",
    "\n",
    "| mean | known model | unknown model |\n",
    "|------|-------------|---------------|\n",
    "| 0.7852028639618138 | 0.7791044776119403 | 0.8095238095238095 |\n",
    "\n",
    "After submission, it scored **0.76555**, the second best record to date after jd second attempt\n",
    "\n",
    "---\n",
    "\n",
    "### 2nd attempt\n",
    "Increased tuning steps from 3500 to 4000 in the unknown model due to the target acceptance warning\n",
    "\n",
    "| mean | known model | unknown model |\n",
    "|------|-------------|---------------|\n",
    "| 0.7852028639618138 | 0.7940298507462686 | 0.75 |\n",
    "\n",
    "**What!** the same mean as the first attempt, let's give it another go before submitting:\n",
    "\n",
    "| mean | known model | unknown model |\n",
    "|------|-------------|---------------|\n",
    "| 0.8042959427207638 |  0.8059701492537313 | 0.7976190476190477 |\n",
    "\n",
    "This second attempt performed nice on training data, but however it only scored **0.64593** on kaggle. Maybe it's overfitting?\n",
    "\n",
    "---\n",
    "\n",
    "### 3rd attempt\n",
    "\n",
    "| mean | known model | unknown model |\n",
    "|------|-------------|---------------|\n",
    "| 0.766109785202864 |  0.7791044776119403 | 0.7142857142857143 |\n",
    "\n",
    "This third attempt performed worse on training data, but improved previous score **0.68421** on kaggle. Still overfitting?\n",
    "\n",
    "---\n",
    "\n",
    "### 4th attempt\n",
    "The following day I submitted the last prediction. scoring **0.73684**\n",
    "\n",
    "| mean | known model | unknown model |\n",
    "|------|-------------|---------------|\n",
    "| 0.7995226730310262 |  0.8 | 0.7976190476190477 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience cleaning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clean(df, cabins=False, titles=False):\n",
    "    \"\"\"Convenience method to clean and prepare the data.\n",
    "    \n",
    "    Arguments: a pandas dataframe\n",
    "    returns: a cleaned dataframe and the cabins & titles ratio for the\n",
    "    test dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Let's assign nan fares to -1\n",
    "    df.Fare.fillna(-.5, inplace=True)\n",
    "    \n",
    "    # Let's make sex a number\n",
    "    idx = df[df.Sex == 'female'].index\n",
    "    df.loc[:, 'Sex'] = 0\n",
    "    df.loc[idx, 'Sex'] = 1\n",
    "    \n",
    "    \n",
    "    # Simplify cabin names and encode by fatality ratio\n",
    "    df.loc[:, 'Cabin'] = df.Cabin.fillna('N')\n",
    "    df.loc[:, 'Cabin'] = df.Cabin.apply(lambda x: x[0])\n",
    "    try:\n",
    "        cabins.all()\n",
    "    except AttributeError:\n",
    "        cabins = df.pivot_table(\n",
    "            index='Cabin', columns='Survived', values='Sex', aggfunc='count').fillna(0)\n",
    "        cabins['ratio'] = cabins[1] / cabins[0]\n",
    "    df = pd.merge(\n",
    "        df, cabins.ratio, left_on='Cabin', right_index=True, how='left')\n",
    "    df.drop(columns=['Cabin',], inplace=True)\n",
    "    df.rename(columns={'ratio': 'Cabin'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Get the name titles and encode by fatality ratio\n",
    "    d1 = df.Name.apply(lambda x: x.split(',')[1].split('.')[0])\n",
    "    df['Title'] = d1.str.replace(' ', '')\n",
    "\n",
    "    # A couple of irregular ones\n",
    "    d1 = df[df.Title.str.contains('Jonkheer')]\n",
    "    d2 = df[df.Title.str.contains('Countess')]\n",
    "    df.loc[d1.index, 'Title'] = 'Mr'\n",
    "    df.loc[d2.index, 'Title'] = 'Mrs'  # In her Age group are majority\n",
    "    \n",
    "    try:\n",
    "        titles.all()\n",
    "    except AttributeError:\n",
    "        titles = df.pivot_table(index='Title', columns='Survived', values='Sex', aggfunc='count').fillna(0)\n",
    "        titles['ratio'] = (titles[1]+1) / (titles[0]+1)\n",
    "    df = pd.merge(df, titles['ratio'], left_on='Title', right_index=True, how='left')\n",
    "    df.drop(columns=['Title',], inplace=True)\n",
    "    df.rename(columns={'ratio': 'Title'}, inplace=True)\n",
    "    \n",
    "    # Finally, drop some columns\n",
    "    df.drop(\n",
    "        columns=['Ticket', 'Embarked', 'Name', 'PassengerId'], inplace=True)\n",
    "    \n",
    "    return df, cabins, titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data and train\n",
    "We'll code in parallel both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare the data\n",
    "nan_ages = df.Age.isna()\n",
    "kdf, udf = df[~nan_ages].copy(), df[nan_ages].copy()\n",
    "kdf, cabins, titles = clean(kdf)\n",
    "udf, _, _= clean(udf, cabins=cabins)\n",
    "udf.drop(columns='Age', inplace=True)\n",
    "\n",
    "### Split the data\n",
    "test_size = testdf.shape[0] / df.shape[0]\n",
    "k_train, k_test = train_test_split(\n",
    "    kdf, test_size=test_size)\n",
    "u_train, u_test = train_test_split(\n",
    "    udf, test_size=test_size)\n",
    "\n",
    "### Training\n",
    "k_feat = [\n",
    "    'Survived', 'Sex', 'Pclass', 'Fare', 'Cabin', 'Title', 'Age' ]\n",
    "u_feat = k_feat[:-1]\n",
    "\n",
    "k_model = 'Survived ~ Sex + Pclass + Fare + Cabin + Title + Age'\n",
    "u_model = k_model[:-6]\n",
    "\n",
    "with pm.Model() as k_logit:\n",
    "    pm.glm.GLM.from_formula(\n",
    "        k_model, k_train[k_feat],\n",
    "        family=pm.glm.families.Binomial())\n",
    "    k_trace = pm.sample(3000, tune=3500, init='adapt_diag')\n",
    "\n",
    "with pm.Model() as u_logit:\n",
    "    pm.glm.GLM.from_formula(\n",
    "        u_model, u_train[u_feat],\n",
    "        family=pm.glm.families.Binomial())\n",
    "    u_trace = pm.sample(3000, tune=4000, init='adapt_diag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build some convenience dataframes\n",
    "We'll make three dataframes:\n",
    "1. Bayesian point estimates, to compare between known and unknown models\n",
    "2. Linear model, logit, prediction, ground truth for known ages\n",
    "3. Linear model, logit, prediction, ground truth for unknown ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_idx = ['Intercept', ] + k_feat[1:]\n",
    "u_idx = ['Intercept', ] + u_feat[1:]\n",
    "\n",
    "# Come up with simple bayesian points for coefficients and intercept\n",
    "k_bp = [k_trace[f].mean() for f in k_idx]\n",
    "u_bp = [u_trace[f].mean() for f in u_idx]\n",
    "\n",
    "data = {\n",
    "    'k_data': k_bp,  # coefficients known age\n",
    "    'u_data': u_bp + [np.nan, ],  # coefficients unknown age (=> as nan) \n",
    "}\n",
    "\n",
    "bayesian_points = pd.DataFrame(data=data, index=k_idx)\n",
    "\n",
    "# linear model\n",
    "k_lm = (k_test.T.reindex(k_idx).fillna(1).T * np.array(k_bp)).sum(axis=1)\n",
    "u_lm = (u_test.T.reindex(u_idx).fillna(1).T * np.array(u_bp)).sum(axis=1)\n",
    "\n",
    "# logistic function\n",
    "def logit(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "k_logit, u_logit = [\n",
    "    logit(x) for x in (k_lm, u_lm)] \n",
    "\n",
    "# Build the predictions df for known ages\n",
    "k_model = pd.concat((k_lm, k_logit), axis=1, keys=('lm', 'logit',))\n",
    "k_model['y'] = k_test.Survived\n",
    "k_model['y_hat'] = 0\n",
    "survived = k_model.logit > .5\n",
    "k_model.loc[k_model[survived].index, 'y_hat'] = 1\n",
    "k_model['matched'] = k_model.y == k_model.y_hat\n",
    "k_model['known_age'] = True\n",
    "\n",
    "# Build the predictions df for unknown ages\n",
    "u_model = pd.concat((u_lm, u_logit), axis=1, keys=('lm', 'logit',))\n",
    "u_model['y'] = u_test.Survived\n",
    "u_model['y_hat'] = 0\n",
    "survived = u_model.logit > .5\n",
    "u_model.loc[u_model[survived].index, 'y_hat'] = 1\n",
    "u_model['matched'] = u_model.y == u_model.y_hat\n",
    "u_model['known_age'] = False\n",
    "\n",
    "model = pd.concat((k_model, u_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = model.known_age == True\n",
    "main = accuracy_score(model.y, model.y_hat)\n",
    "known = accuracy_score(model[f].y, model[f].y_hat)\n",
    "unknown = accuracy_score(model[~f].y, model[~f].y_hat)\n",
    "print('Overall accuracy:', main)\n",
    "print('Known model:     ', known)\n",
    "print('Unknown model:   ', unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, _, _ = clean(testdf, cabins=cabins, titles=titles)\n",
    "f = t0.Age.isna()\n",
    "known, unknown = t0[f], t0[~f]\n",
    "\n",
    "k_lm = (\n",
    "    known.T.reindex(k_idx).fillna(1).T * \n",
    "    bayesian_points.k_data.values).sum(axis=1)\n",
    "u_lm = (\n",
    "    unknown.T.reindex(u_idx).fillna(1).T * \n",
    "    bayesian_points.u_data.values[:-1]).sum(axis=1)\n",
    "\n",
    "lm = pd.concat((k_lm, u_lm))\n",
    "log = logit(lm)\n",
    "survived = log > .5\n",
    "log[survived] = 1\n",
    "log[~survived] = 0\n",
    "log = log.astype(int)\n",
    "log.name = 'Survived'\n",
    "  \n",
    "pd.concat((testdf.PassengerId, log), axis=1).to_csv(\n",
    "    'Submissions/05-bayesian-logistic-regression-splitted-4th-pass.csv', \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
