{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "* The total knowledge of the crowd superseedes the knowledge of even its most intelligent member.\n",
    "* Such knowledge is desirable and we can gain it by aggregation.\n",
    "* Simple averaging is suboptimal (even misleading) in many cases so,\n",
    "* Let's review the methods that counteract the failures of simple averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condorcet theorem\n",
    "#### Where simple averaging returns insights.\n",
    "If the mean probability of people voting right ($p$) is greater than .5, then sucesive elections will render right outcomes with probability greater than $p$ provided that:\n",
    "* a) $p > 0.5$\n",
    "* b) people vote independently\n",
    "\n",
    "Sucesive elections can also be thought as having one huge election (with lots of votes) and subsampling groups.\n",
    "\n",
    "All this means that the group outperforms the individuals in the long run.\n",
    "\n",
    "<img style=\"float:left;\" src=\"img/condorcet.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define rounds of elections and votes per election\n",
    "elections, votes = 10000, 101  # odd votes to avoid draws\n",
    "s0 = pd.DataFrame(\n",
    "    np.random.binomial(1, .7, size=(elections, votes)))\n",
    "\n",
    "# Now count all the times right option wins (1)\n",
    "outcomes = (\n",
    "    (s0 == 1).sum(axis=1) > (s0 == 0).sum(axis=1))\n",
    "\n",
    "print(\n",
    "    'Sucesive elections will render right options',\n",
    "    'with probability {}'.format(outcomes.mean()))\n",
    "print(\n",
    "    'the mean of the sample is {}'.format(\n",
    "        s0.mean().mean().round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Condorcet assumptions no longer hold, we can still assure that the average of opinions outperforms a randomly selected individual by using convex functions and Jensen inequalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen inequalities\n",
    "\n",
    "The loss of the expectation is always less or equal to the expectation of losses. That means that we will fail less if we take the loss of the mean of opinions, rather than takine the mean of the loss of the opinions, so the mean outperforms the individual.\n",
    "\n",
    "$\\varphi(\\mathop{}\\mathbb{E}[X])\\le\\mathop{}\\mathbb{E}[\\varphi(X)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging failure\n",
    "\n",
    "However, averaging methodologies sometimes fail or prove suboptimal. In these cases, we can tackle the problem using different tools:\n",
    "* Full vote procedure\n",
    "* Opinion unbiasing\n",
    "* Wisdom of the resistant\n",
    "* Chosing rather averaging\n",
    "* Wisdom of select crowds\n",
    "\n",
    "[[Index]](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A BRIEF PRIMER ON STATISTICAL DECISION THEORY\n",
    "\n",
    "Statistical decision theory tries to make the most of the information available to take a decision. It studies the factors that influence how to arrive to such decision:\n",
    "\n",
    "1) The relation between the information source and the truth: that is, How much true information is it present in the source?  \n",
    "\n",
    "2) The relations between different information sources: that is, how correlated are the different information sources?  \n",
    "\n",
    "3) The cost induced by the errors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The relationship between the individual opinions and the truth\n",
    "Having quantitative knowledge of the individuals is fairly useful. Probalility distributions and histograms are the most convenient ways to show that quantities. They have 3 main features:\n",
    "* **[Bias](./../Glossary.ipynb#B):** How far the average opinion is from the truth.\n",
    "* **[Variance](./../Glossary.ipynb#V):** how different are the individual opinions to one another.\n",
    "* **The shape of the distribution:** that can match with a known distribution (luckily) or not. In the latter case, when no known distribution matches, one should pay attention to the *[fat tails](./../Glossary.ipynb#F)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging information about biases and shapes\n",
    "When bias are recurrent they can offer ways to improve the collective knowledge: if a certain sub-group recursively, say, understimates the true value, debiasing that amount in the rest should improve their predictions.\n",
    "\n",
    "Also the knowledge of the shape can improve the aggregation strategy: pruning away outliers in a fat tail distribution may improve wisdom of the crowd estimates, or also leaving out a certain percentage of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individuality and Expertise\n",
    "Weighted arithmetic mean works nice when expertise level is different among the indiviuals or even when subgroups are unbalanced.\n",
    "\n",
    "Reduced subgroups of experts outperform the whole crowd and the single (best) expert. The level of expertise can be based on historical accuracy.\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
