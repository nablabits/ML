{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haO_azcBZEH7"
   },
   "source": [
    "# Bayes' theorem and information theory\n",
    "\n",
    "Officially, Bayes' theorem let us update our beliefs when we are given new evidence. Personally, I find Bayes as the key to flip the dependence way. In this example we start out from weather and how it conditions the clothes we are about pick, to work backwards that relation: how clothes *determine* the weather i.e., how can we guess the weather provided that we know the clothes.\n",
    "\n",
    "**Mutual information**\n",
    "That above implies that the weather carries some information about the clothes one wears and the other way arround. The information that both variables share is called mutual information.\n",
    "\n",
    "Nice video visualizing Bayes' theorem [(3b1b)](https://www.youtube.com/watch?v=HZGCoVF3YvM)  \n",
    "Nice explanation about conditional probability and information theory [(Colah's blog)](http://colah.github.io/posts/2015-09-Visual-Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haO_azcBZEH7"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i5Gn2_sZEIF"
   },
   "outputs": [],
   "source": [
    "def entropy(arr):\n",
    "    \"\"\"Compute the entropy of a given array.\"\"\"\n",
    "    return -(arr * np.log2(arr)).sum()\n",
    "\n",
    "def joint(P, Q1, Q2):\n",
    "    \"\"\"Compute the joint probability of two conditioned distributions.\"\"\"\n",
    "    return np.concatenate(((P * Q1), (P * Q2)))\n",
    "\n",
    "def info(arr):\n",
    "    I = np.absolute(arr[:2].sum() - arr[2]).round(3)\n",
    "    print('H(W):               {}'.format(arr[0]))\n",
    "    print('H(C):               {}'.format(arr[1]))\n",
    "    print('H(H, C):            {}'.format(arr[2]))\n",
    "    print('Mutual information: {}'.format(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnNmzgpGZEIL"
   },
   "outputs": [],
   "source": [
    "# Probability of rain/sun P(W)\n",
    "W = np.array([1/4, 3/4])\n",
    "\n",
    "# Probability of clothes given rainy weather P(C|W=R)\n",
    "C_RW = np.array([1/4, 3/4])  # T-shirt, coat\n",
    "\n",
    "# Probability of clothes given sunny weather P(C|W=S)\n",
    "C_SW = np.array([3/4, 1/4])  # T-shirt, coat\n",
    "\n",
    "# Joint probability (W, C)\n",
    "WC = joint(W, C_SW, C_RW)\n",
    "\n",
    "\"\"\"\n",
    "Unpack values for:\n",
    "\n",
    "rain+t-shirt: RT\n",
    "rain+coat:    RC\n",
    "sun+coat:     SC\n",
    "sun+t-shirt:  ST\n",
    "So we can compute Bayes' theorem\n",
    "\"\"\"\n",
    "RC, SC, RT, ST = WC\n",
    "\n",
    "# Probability of coat/t-shirt P(C)\n",
    "C = np.array([RC+SC, RT+ST])\n",
    "\n",
    "# Probability of weather given t-shirt P(W|C=T-shirt)\n",
    "W_CT = np.array([ST/(ST+RT), RT/(ST+RT)]) # [.9, .1]\n",
    "\n",
    "# Probability of weather given coat P(W|C=coat)\n",
    "W_CC = np.array([SC/(SC+RC), RC/(SC+RC)])  # [.5, .5]\n",
    "\n",
    "# Finally compute informations\n",
    "e0 = np.array([entropy(p) for p in (W, C, WC)]).round(3)\n",
    "info(e0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "entropy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
